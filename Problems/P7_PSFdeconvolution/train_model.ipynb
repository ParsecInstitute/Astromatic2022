{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c4dd742-20fb-46c7-aed2-e4ca488813c9",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "This notebook provides an example of a training loop, and contains some utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1cac1a-83f9-4d51-8d10-47efc162cbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "import os\n",
    "import json\n",
    "from glob import glob\n",
    "import argparse\n",
    "import copy\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam, Adamax\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "\n",
    "from utils.display_utils import loss_curves, display_x_y, display_progress\n",
    "from torch_datasets import PSFDataset\n",
    "from vanilla_cnn_solution import VanillaCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3de8ac6-0faf-408e-b1af-252f2b87113e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_logs(logs_dic, path_out, iter, filename):\n",
    "\tlogs_df = pd.DataFrame(data=logs_dic, index=[0])\n",
    "\n",
    "\tif iter == 1:\n",
    "\t\twmode = \"w\"\n",
    "\t\theader = True\n",
    "\telse:\n",
    "\t\twmode = \"a\"\n",
    "\t\theader = False\n",
    "\n",
    "\twith open(os.path.join(path_out, \"logs\", filename), mode=wmode) as csv_file:\n",
    "\t\tlogs_df.to_csv(csv_file, header=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1c53b7-2032-4b02-aeb0-eb68d09d219a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,\n",
    "\t\t\t  dataset_dir,\n",
    "\t\t\t  data_size,\n",
    "\t\t\t  loss_fn,\n",
    "\t\t\t  optimizer,\n",
    "\t\t\t  lr,\n",
    "\t\t\t  model_name,\n",
    "\t\t\t  save_model_every,\n",
    "\t\t\t  plot,\n",
    "\t\t\t  plot_every,\n",
    "\t\t\t  style,\n",
    "\t\t\t  exp_path,\n",
    "\t\t\t  batch_size,\n",
    "\t\t\t  epochs,\n",
    "\t\t\t  device=torch.device(\"cpu\")):\n",
    "\n",
    "\tcriterion = loss_fn().to(device, non_blocking=True)\n",
    "\toptimizer = optimizer(model.parameters(), lr=lr)\n",
    "\n",
    "\tstart = time.time()\n",
    "\n",
    "\tdataset = PSFDataset(dir_path=dataset_dir, size=data_size, val_frac=0.2, test_frac=0.2)\n",
    "\tdisplay_norm = None\n",
    "\n",
    "\tepoch_header = True\n",
    "\tstep = 0\n",
    "\n",
    "\tfor epoch in tqdm(range(1, epochs + 1)):\n",
    "\n",
    "\t\tdataset.method = \"train\"\n",
    "\t\ttrain_dataloader = DataLoader(copy.copy(dataset), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\t\tdataset.method = \"val\"\n",
    "\t\tval_dataloader = DataLoader(copy.copy(dataset), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\t\tprint('\\n')\n",
    "\t\tprint(f'Epoch {epoch}/{epochs}')\n",
    "\t\tprint('-' * 10)\n",
    "\t\t\n",
    "\t\tepoch_logs = {\"epoch\": epoch}\n",
    "\n",
    "\t\tfor phase in [\"valid\", \"train\"]:\n",
    "\n",
    "\t\t\tif phase == \"train\":\n",
    "\t\t\t\tmodel.train(True)\n",
    "\t\t\t\tdataloader = train_dataloader\n",
    "\t\t\telse:\n",
    "\t\t\t\tmodel.train(False)\n",
    "\t\t\t\tdataloader = val_dataloader\n",
    "\n",
    "\t\t\trunning_loss = 0.\n",
    "\n",
    "\t\t\tfor i, (x, y) in enumerate(dataloader):\n",
    "\t\t\t\tx = x.to(device, non_blocking=True)\n",
    "\t\t\t\ty = y.to(device, non_blocking=True)\n",
    "\n",
    "\t\t\t\t# training phase\n",
    "\t\t\t\tif phase == \"train\":\n",
    "\t\t\t\t\t# display what the data looks like\n",
    "\t\t\t\t\tif i == 0 and epoch == 1 and plot:\n",
    "\t\t\t\t\t\tdset_name = os.path.basename(dataset_dir)\n",
    "\t\t\t\t\t\tdisplay_x_y(x.cpu().detach().numpy(), y.cpu().detach().numpy(), dset_name, size=5, norm=display_norm, style=style)\n",
    "\n",
    "\t\t\t\t\tmodel.zero_grad()\n",
    "\n",
    "\t\t\t\t\tyhat = model(x)\t\t\t\t\t# forward pass\n",
    "\t\t\t\t\tloss = criterion(yhat, y)\t\t# evaluate loss\n",
    "\t\t\t\t\tloss.backward()\t\t\t\t\t# backward pass\n",
    "\n",
    "\t\t\t\t\toptimizer.step()\t\t\t\t# update network\n",
    "\n",
    "\t\t\t\t\tstep += 1\n",
    "\n",
    "\t\t\t\t\tif plot and epoch%plot_every == 0 and i == 0:\n",
    "\t\t\t\t\t\tdisplay_progress(x.cpu().detach().numpy(), yhat.cpu().detach().numpy(), y.cpu().detach().numpy(), epoch, norm=display_norm, style=style)\n",
    "\n",
    "\t\t\t\t# validation phase\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\twith torch.no_grad():\n",
    "\t\t\t\t\t\tyhat = model(x)\n",
    "\t\t\t\t\t\tloss = criterion(yhat, y)\n",
    "\n",
    "\t\t\t\t# update cumulative values\n",
    "\t\t\t\trunning_loss += float(loss.detach())\n",
    "\n",
    "\t\t\t# after all batches processed\n",
    "\t\t\tepoch_loss = running_loss / dataloader.__len__()\n",
    "\n",
    "\t\t\t# epoch_logs = {\"epoch\": epoch,\n",
    "\t\t\t\t\t\t  # f\"{phase}_loss\": epoch_loss}\n",
    "\t\t\t\n",
    "\t\t\tepoch_logs.update({f\"{phase}_loss\": epoch_loss})\n",
    "\t\t\t\n",
    "\t\t\tif phase == \"train\":\n",
    "\t\t\t\tepoch_logs.update({\"lr\": optimizer.param_groups[0]['lr']})\n",
    "\n",
    "\t\t\t# display progress\n",
    "\t\t\tprint(f'epoch {epoch} ==>  {phase} loss: {epoch_loss:.4e}')\n",
    "\n",
    "\t\tsave_logs(epoch_logs, exp_path, epoch, f\"logs.csv\")\n",
    "\t\t\n",
    "\t\t# Keeping track of the model\n",
    "\t\tif save_model_every is not None:\n",
    "\t\t\tif epoch % save_model_every == 0:\n",
    "\t\t\t\ttorch.save(model.state_dict(), exp_path + f'/models/{model_name}_epoch_{epoch:03d}.pt')\n",
    "\n",
    "\t# print training time\n",
    "\ttime_elapsed = time.time() - start\n",
    "\tprint(f'Training completed in {(time_elapsed // 60):.0f}m {(time_elapsed % 60):.0f}s')\n",
    "\n",
    "\t# **Save model**\n",
    "\ttorch.save(model.state_dict(), exp_path + \"/models/\" + f\"{model_name}_complete.pt\")\n",
    "\n",
    "\treturn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f66a71f-27ee-4e5b-8ee8-2bd9d6384857",
   "metadata": {},
   "source": [
    "### Experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7213b37-264e-4aef-900a-e240a50e7c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_in = os.path.join(os.getenv(\"ASTROMATIC_PATH\"))\n",
    "path_out = os.path.join(os.getenv(\"ASTROMATIC_PATH\"), \"Problems\", \"P7_PSFdeconvolution\")\n",
    "exp_name = \"debug\"\n",
    "dataset = \"debug_deconv_dataset_2\"\n",
    "npix = 256\n",
    "data_size = None\n",
    "batch_size = 10\n",
    "n_epochs = 3\n",
    "lr = 5e-3\n",
    "loss = \"MSE\"\n",
    "optimizer = \"Adamax\"\n",
    "nla = \"ReLU\"\n",
    "model_type = \"VanillaCNN\"\n",
    "model_name = \"debug_model\"\n",
    "save_model_every = 20\n",
    "plot = True\n",
    "plot_every = n_epochs\n",
    "plt_style = \"science\"\n",
    "seed = 0\n",
    "\n",
    "exp_path = os.path.join(path_out, \"experiments\", exp_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa259ce-fa95-4683-a468-5d195869664a",
   "metadata": {},
   "source": [
    "### Experiment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da0a1ad-5439-4bc2-ac82-7b261b915100",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "if not os.path.exists(os.path.join(exp_path, \"models\")):\n",
    "\tos.makedirs(os.path.join(exp_path, \"models\"))\n",
    "if not os.path.exists(os.path.join(exp_path, \"logs\")):\n",
    "\tos.makedirs(os.path.join(exp_path, \"logs\"))\n",
    "\t\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# - loss function -\n",
    "if loss == \"MSE\":\n",
    "\tloss_fct = nn.MSELoss\n",
    "\n",
    "# - optimizer -\n",
    "if optimizer == \"Adamax\":\n",
    "\toptimizer = Adamax\n",
    "\n",
    "in_ch = 2\n",
    "out_ch = 1\n",
    "\n",
    "# --- Model ---\n",
    "if model_type == \"VanillaCNN\":\n",
    "\tmodel = VanillaCNN(npix=npix, in_ch=in_ch, out_ch=out_ch, activation=nla).float()\n",
    "else:\n",
    "\traise ValueError(f\"model of type {model_type} not found\")\n",
    "\n",
    "print(summary(model, input_size=(batch_size, in_ch, npix, npix)))\n",
    "\n",
    "model = model.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd04107b-1248-4945-8dfc-ccc57783c25c",
   "metadata": {},
   "source": [
    "### Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca3fd70-f8f7-49a0-817e-61960b28941f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model=model,\n",
    "\t\t   dataset_dir=os.path.join(path_out, \"datasets\", dataset),\n",
    "\t\t   data_size=data_size,\n",
    "\t\t   loss_fn=loss_fct,\n",
    "\t\t   optimizer=optimizer,\n",
    "\t\t   lr=lr,\n",
    "\t\t   model_name=model_name,\n",
    "\t\t   save_model_every=save_model_every,\n",
    "\t\t   plot=plot,\n",
    "\t\t   plot_every=plot_every,\n",
    "\t\t   style=plt_style,\n",
    "\t\t   exp_path=exp_path,\n",
    "\t\t   batch_size=batch_size,\n",
    "\t\t   epochs=n_epochs,\n",
    "\t\t   device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331de892-7242-4032-b4a4-2c5583429c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot:\n",
    "\tloss_curves(exp_path, loss, model_name=model_name, save=False, style=plt_style)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
